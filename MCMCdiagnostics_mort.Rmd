---
 title: "MCMC diagnostics - Mortality"
 subtitle: "Test v10.0 - plot random effect"
 author: "Will Vieira"
 date: "`r paste('Last updated on', format(Sys.time(), '%d %B, %Y'))`"
---


## Diagnostics for the Von Bertalanffy model

```{r, echo = F, message=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(data.table))
suppressPackageStartupMessages(library(cmdstanr))
suppressPackageStartupMessages(library(loo))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(purrr))
suppressPackageStartupMessages(library(ggpubr))
suppressPackageStartupMessages(library(tidybayes))
suppressPackageStartupMessages(library(bayesplot))
suppressPackageStartupMessages(library(ggridges))
suppressPackageStartupMessages(require(RColorBrewer))
suppressPackageStartupMessages(library(DT))
```


```{r load simulations, echo = F}
# Load simulation variables
simInfo <- yaml::read_yaml('_simulation_info.yml')

spIds <- simInfo$spIds
simName <- simInfo$simName
simulations <- simInfo$simulations

# List output files and set vector names to species_id
posteriorPop_files <- grep(
  'posteriorPop',
  dir(file.path('output', simName), full.names = TRUE),
  value = TRUE
)
names(posteriorPop_files) <- names(sort(sapply(spIds, function(x) grep(x, posteriorPop_files))))

posteriorrPlot_files <- grep(
  'posteriorpsiPlot',
  dir(file.path('output', simName), full.names = TRUE),
  value = TRUE
)
names(posteriorrPlot_files) <- names(sort(sapply(spIds, function(x) grep(x, posteriorrPlot_files))))

# posteriorrTree_files <- grep(
#   'posteriorrTree',
#   dir(file.path('output', simName), full.names = TRUE),
#   value = TRUE
# )
# names(posteriorrTree_files) <- names(sort(sapply(spIds, function(x) grep(x, posteriorrTree_files))))

diag_files <- grep(
  'diagnostics',
  dir(file.path('output', simName), full.names = TRUE),
  value = TRUE
)
names(diag_files) <- names(sort(sapply(spIds, function(x) grep(x, diag_files))))

trainData_files <- grep(
  'trainData',
  dir(file.path('output', simName), full.names = TRUE),
  value = TRUE
)
names(trainData_files) <- names(sort(sapply(spIds, function(x) grep(x, trainData_files))))
```

```{r load dataset,echo =FALSE}
trainData <- map2_dfr(
  trainData_files,
  names(trainData_files),
  ~ readRDS(.x)
)

mort_dt <- readRDS('data/mort_dt.RDS')
mort_dt <- mort_dt[species_id %in% spIds]

# merge with train data
mort_dt[
  trainData,
  sampled := i.sampled,
  on = c('tree_id', 'year0')
]

# add species_id to trainData
trainData[
  mort_dt,
  `:=`(
    'plot_id' = i.plot_id,
    'species_id' = i.species_id,
    'deltaYear' = i.deltaYear,
    'mort' = i.mort,
    'dbh0' = i.dbh0,
    'BA_comp_sp' = i.BA_comp_sp,
    'BA_comp_intra' = i.BA_comp_intra,
    'bio_01_mean' = i.bio_01_mean,
    'bio_12_mean' = i.bio_12_mean
  ),
  on = c('tree_id', 'year0')
]

# summary by plot_id and tree_id
plot_id_summary <- mort_dt[, 
    .(
      latitude = unique(latitude),
      BA_plot = mean(BA_plot),
      bio_01_mean = mean(bio_01_mean),
      bio_12_mean = mean(bio_12_mean)
    ), 
    by = plot_id
  ]

tree_id_summary <- mort_dt[, 
    .(
      plot_id = unique(plot_id),
      dbh0 = mean(dbh0, na.rm = TRUE),
      BA_comp = mean(BA_comp, na.rm = TRUE),
      bio_01_mean = mean(bio_01_mean, na.rm = TRUE)
    ), 
    by = tree_id
  ]
```

# Rhat

```{r rhat, echo = F, fig.height = 7, fig.width = 7}
map2_dfr(
  diag_files,
  names(diag_files),
  ~ readRDS(.x)[['rhat']] |>
      bind_cols(species_id = .y)
) |>
ggplot(aes(x = rhat, y = species_id)) +
  geom_boxplot() +
  theme_minimal()
```



# Divergent transitions

```{r divergentTransitions, echo = FALSE}
map2_dfr(
  diag_files,
  names(diag_files),
  ~ readRDS(.x)[['diag_summary']]['num_divergent'] |>
      bind_cols(species_id = .y) |>
      mutate(chain = row_number())
) |>
pivot_wider(
  names_from = chain,
  values_from = num_divergent,
  names_prefix = 'chain '
) |>
DT::datatable()
```



# Posterior distribution of parameters

```{r posteriorDist, eval = TRUE,echo = F, fig.height = 7, fig.width = 8}
post <- map2_dfr(
  posteriorPop_files,
  names(posteriorPop_files),
  ~ readRDS(.x) |>
    bind_cols(species_id = .y)
)

for(Par in unique(post$par))
{
  print(
    post |>
      filter(par == Par) |>
      ggplot(aes(x = value, y = species_id)) +
        stat_eye() +
        ggtitle(Par) +
        xlab('') +
        theme_minimal()
  )
}
```


# Correlation between parameters

```{r parCorrelation, eval = TRUE,echo = F, fig.height = 8, fig.width = 8}
parComb <- post |>
  summarise(uqPar = unique(par)) |>
  pull(uqPar) |>
  combn(2)

for(i in 1:ncol(parComb))
{
  print(
    post |>
      filter(par %in% parComb[, i]) |>
      filter(iter %in% sample(iter, 1000)) |>
      select(par, value, iter, species_id) |>
      pivot_wider(names_from = par, values_from = value) |>
      ggplot(aes_string(x = parComb[1, i], y = parComb[2, i])) + 
          geom_point() +
          facet_wrap(~ species_id) +
          xlab(parComb[1, i]) +
          ylab(parComb[2, i]) +
          theme_minimal()
  )
}
```


# Plot random effect

```{r plot_randomEffect, eval = TRUE, warning=FALSE, message=FALSE,echo = F, fig.height = 8, fig.width = 8}
plotEffect_ls <- list()
# treeEffect_ls <- list()
for(Sp in spIds)
{
    psi_pop <- post |>
        filter(species_id == Sp & par == 'psi') |>
        mutate(psi_pop = value) |>
        select(psi_pop, iter)

    psi_mean <- psi_pop |>
        summarise(psi_mean = mean(exp(psi_pop))) |>
        pull(psi_mean)

    dt_toPlot <- readRDS(posteriorrPlot_files[Sp]) |>
            mutate(plot_id_seq = parse_number(par)) |>
            left_join(
              psi_pop
            ) |>
            mutate(
              psiPlot = value,
              psi_natural = exp(psiPlot + psi_pop)
            ) |>
            select(!value) |>
            left_join(
              trainData[
                species_id == Sp & !is.na(plot_id_seq),
                .(plot_id = unique(plot_id)),
                by = plot_id_seq
              ]
            ) |>
            left_join(
              plot_id_summary
            )
    
    # dt_toTree <- readRDS(posteriorrTree_files[Sp]) |>
    #         mutate(tree_id_seq = parse_number(par)) |>
    #         left_join(
    #           psi_pop
    #         ) |>
    #         mutate(psi_natural = exp(value + psi_pop)) |>
    #         left_join(
    #           trainData[
    #             species_id == Sp & !is.na(tree_id_seq),
    #             .(tree_id = unique(tree_id)),
    #             by = tree_id_seq
    #           ]
    #         ) |>
    #         left_join(
    #           tree_id_summary
    #         )

      # save plot effect mean to plot against other variables
      # in the next code block
      plotEffect_ls[[Sp]] <- dt_toPlot |>
          group_by(par) |>
          mutate(
            psi_natural_mean = mean(psi_natural),
            psi_pop = exp(psi_pop)
          ) |>
          ungroup() |>
          filter(iter == 1) |>
          select(
            plot_id, plot_id_seq, psi_pop, psi_natural_mean, latitude,
            BA_plot, bio_01_mean, bio_12_mean
          )

      # treeEffect_ls[[Sp]] <- dt_toTree |>
      #     group_by(par) |>
      #     mutate(
      #       psi_natural_mean = mean(psi_natural),
      #       r_pop = exp(r_pop)
      #     ) |>
      #     ungroup() |>
      #     filter(iter == 1) |>
      #     select(
      #       tree_id, tree_id_seq, r_pop, psi_natural_mean, dbh, BA_comp, bio_01_mean
      #     )

      # filter tree_ids within plots with higher number of individuals
      # plots_toKeep <- dt_toTree |>
      #     filter(iter == 1) |>
      #     group_by(plot_id) |>
      #     summarise(nInd = n()) |>
      #     arrange(desc(nInd)) |>
      #     mutate(cumInd = cumsum(nInd)) |>
      #     filter(cumInd < 500) |>
      #     pull(plot_id)
      
      # dt_toTree <- dt_toTree |>
      #     filter(plot_id %in% plots_toKeep) |>
      #     left_join(
      #       dt_toPlot |>
      #         select(plot_id, iter, plot_id_seq, rPlot_log)
      #     ) |>
      #     arrange(plot_id_seq) |>
      #     mutate(
      #       psi_naturalPlotTree = exp(value + r_pop + rPlot_log)
      #     )

    print(
    #   ggarrange(
          dt_toPlot |>
              filter(plot_id_seq %in% sample(plot_id_seq, 800)) |>
              mutate(plot_id = fct_reorder(plot_id, latitude)) |>
              ggplot(aes(y = plot_id, x = psi_natural, color = bio_01_mean)) +
                stat_pointinterval(alpha = .7, size = .1) +
                geom_vline(
                  xintercept = psi_mean, color = 'red', alpha = .8
                ) +
                xlab('Longevity (years)') +
                ylab('plot_id (ordered by latitude)') +
                theme(
                  legend.position = 'top',
                  axis.text.y = element_blank()
                ) +
                labs(subtitle = Sp)#,
    #       dt_toTree |>
    #           ggplot(aes(y = tree_id, x = psi_naturalPlotTree, color = plot_id)) +
    #             stat_pointinterval(alpha = .7, size = .1) +
    #             geom_vline(
    #               xintercept = psi_mean, color = 'red', alpha = .8
    #             ) +
    #             xlab('Longetivity') +
    #             ylab('tree_id (color grouped by plot_id)') +
    #             theme(
    #               legend.position = 'none',
    #               axis.text.y = element_blank()
    #             ) +
    #             labs(subtitle = ''),
    #       ncol = 2
    #   )
    )
}

# save plot effect ot be used against future models
plotEffect <- plotEffect_ls |>
  bind_rows(.id = 'species_id')

plotEffect |>
  select(species_id, plot_id, psi_natural_mean) |>
  saveRDS(
    file.path(
        'output', 
        simName,
        'meanPlotEffect_psi.RDS'
    )
  )

# treeEffect <- treeEffect_ls |>
#   bind_rows(.id = 'species_id')

# treeEffect |>
#   select(species_id, tree_id, r_pop, psi_natural_mean) |>
#   saveRDS(
#     file.path(
#         'output', 
#         simName,
#         'meanTreeEffect_rReal.RDS'
#     )
#   )
```

# Correlation in plot random effects between species

```{r corrPlotEffect, echo = FALSE, warning=FALSE, message=FALSE, fig.height=12, fig.width = 14}

# load parameters
post_mean <- post |>
  filter(par == 'psi') |>
  group_by(species_id) |>
  summarise(psi = mean(value))

psiPlot_mean <- readRDS('output/mort_plot/meanPlotEffect_psi.RDS') |>
  left_join(
    post_mean
  ) |>
  mutate(
    psiPlot = log(psi_natural_mean) - psi
  )

# count number of plots per species pair
uqSp_plot <- psiPlot_mean |>
  group_by(plot_id) |>
  summarise(
        uqSp = unique(species_id),
        nbSp = length(uqSp)
    ) |>
    filter(nbSp > 1)

# number of plots per species pair
nbPlot_sp <- spIds |>
  combn(2) |>
  array_branch(margin = 2) |>
  map_dfr(
    ~ tibble(
        sp1 = .x[1],
        sp2 = .x[2],
        nbPlot = uqSp_plot |>
            filter(uqSp %in% c(.x[1], .x[2])) |>
            group_by(plot_id) |>
            summarise(nbSp = length(unique(uqSp))) |>
            filter(nbSp > 1) |>
            summarise(nPlot = n()) |>
            pull(nPlot)
    )
  )

# Filter for a minimum of plots per sp pair to create plot code
plot_code <- nbPlot_sp |>
    filter(nbPlot > 500) |>
    mutate(plot_code = paste(sp1, sp2, sep = ' vs ')) |>
    pivot_longer(
        cols = contains('sp'),
        values_to = 'species_id',
        names_to = 'axis'
    ) |>
    select(species_id, axis, plot_code)

psiPlot_mean |>
    filter(species_id %in% unique(plot_code$species_id)) |>
    left_join(
        plot_code
    ) |>
    select(plot_id, psiPlot, axis, plot_code) |>
    pivot_wider(
        names_from = 'axis',
        values_from = psiPlot
    ) |>
    ggplot(aes(sp1, sp2)) +
        geom_point(size = .4, alpha = 0.6) + 
        geom_smooth() +
        facet_wrap(~plot_code) +
        theme_minimal() +
        xlim(-1.5, 1.5) + ylim(-1.5, 1.5)
```

# Changes in plot random effect from past models

Compare plot random effect with last model to check how variance is changing. 

```{r compare_rReal, echo = FALSE, warning=FALSE, message=FALSE, fig.height = 8, fig.width = 12}
sim_to_compare <- simInfo$simCompare

# for(Sim in sim_to_compare)
# {
#   sim_toLoad <- c(Sim, simName)
    
#   print(
#     map_dfr(
#       sim_toLoad,
#       ~ readRDS(file.path('output', .x, 'meanPlotEffect_rReal.RDS')) |>
#         bind_cols(sim = .x)
#     ) |>
#     pivot_wider(
#       names_from = sim,
#       values_from = psi_natural_mean
#     ) |>
#     ggplot(aes(x = !!sym(sim_toLoad[1]), y = !!sym(sim_toLoad[2]))) +
#       geom_point(size = 0.8, alpha = .7) +
#       geom_abline(intercept = 0, slope = 1) +
#       #tune::coord_obs_pred() +
#       facet_wrap(~species_id, scales = 'free') +
#       theme_minimal()
#   )
# }
```


# Data distribution

```{r organize data, echo = FALSE, warning=FALSE, message=FALSE, fig.height = 10, fig.width = 8}
# split between train and everything else (merge validate with rest of data)
mort_dt[, sampled2 := sampled]
mort_dt[is.na(sampled), sampled2 := 'validation']

mort_dt[, .(species_id, dbh0, deltaYear, BA_comp_sp, BA_comp_intra, bio_01_mean, bio_12_mean, sampled2)] |>
  mutate(sample = sampled2) |>
  pivot_longer(
    cols = c(dbh0, deltaYear, BA_comp_sp, BA_comp_intra, bio_01_mean, bio_12_mean),
    names_to = 'var'
  ) |>
  ggplot(aes(x = value, y = species_id, fill = sample)) +
    geom_density_ridges(alpha = 0.7, color = NA) +
    facet_wrap(~var, scales = 'free_x') +
    xlab('') +
    theme_minimal() +
    theme(legend.position = 'top')
```



# Predictions

## Longevitity `exp(psi)`

```{r sizePred,echo=FALSE,fig.height = 6.5, fig.width = 7}
post |>
  filter(par == 'psi') |>
  mutate(long = exp(value)) |>
  ggplot(aes(x = long, y = species_id)) +
    ggridges::geom_density_ridges2(color = NA, alpha = 0.8) +
    theme_minimal() +
    xlab('Longevity (years)')
```

## Accuracy

Using four different metrics:

- **Sensitivity** measures the percentage of dead trees that are identified as dead
- **Specificity** measures the percentage of alive trees that are correctly identified as alive
- **Accuracy** is the ratio of number of correct predictions to the total of predictions
- **Accuracy balanced** considers unbalanced accuracy predictions of positive and negative events (sensitivity and specificity)

```{r plot_accur, echo = FALSE, warning=FALSE, message=FALSE, fig.height = 12, fig.width = 9}
# list accuracy db for each species
accur_ls <- mortProp_ls <- list()

for(Sp in spIds)
{
  train_sp <- trainData[species_id == Sp & sampled == 'training']

  # replicate each observation by N_iteration to accommodate the parameters draw
  # Using only 300 iterations of the 8000 to speed calculation as the final
  # result is quite similar to use the 8000 iteractions
  train_sp[, obsID := .I]
  train_sp <- train_sp[rep(obsID, each = 300)]
  sampledIter <- sample(1:(simInfo$maxIter/2 * simInfo$nC), 300)
  train_sp[, iter := sampledIter, by = obsID]

  # merge global parameters
  train_sp[
    post |>
        filter(species_id == Sp) |>
        select(-species_id) |>
        pivot_wider(names_from = par, values_from = value) |>
        setDT(),
    `:=`(
      psi = i.psi,
      sigma_plot = i.sigma_plot
    ),
    on = 'iter'
  ]
  
  # merge plot_id parameters if plot is present in validation data
  train_sp[
    readRDS(posteriorrPlot_files[Sp]) |>
      mutate(
        plot_id_seq = parse_number(par)
      ) |>
      select(!par) |>
      setDT(),
    psiPlot := i.value,
    on = c('iter', 'plot_id_seq')
  ]

  # random iter were selected, create a new iter vetor to a proprer sequence
  # from 1 to nSample of iteration
  train_sp[, iter2 := 1:.N, by = obsID]

  # compute longevity logit
  train_sp[,
    longev_log := 1/(1 + exp(
        -psi + 
        psiPlot
      )
    )
  ]

  # compute mortality rate in function of time
  train_sp[,
    mortality_prob := 1 - (longev_log^deltaYear)
  ]

  # predict mortality event
  train_sp[,
    mort_pred := rbinom(.N, size = 1, mortality_prob)
  ]

  # Compute model accuracy
  accur_ls[[Sp]] <- train_sp |>
    group_by(iter2) |>
    summarise(
      TP = sum(mort == 1 & mort_pred == 1),
      TN = sum(mort == 0 & mort_pred == 0),
      FN = sum(mort == 1 & mort_pred == 0),
      FP = sum(mort == 0 & mort_pred == 1)
    ) |>
    mutate(
      Acc = (TP + TN)/(TP + TN + FP + FN),
      Sensitivity = TP/(TP + FN),
      Specificity = TN/(FP + TN),
      AccCorrected = (Sensitivity + Specificity)/2
    ) |>
    bind_cols(species_id = Sp)

  # Compute proportion of mortality events (pred vs obs)
  mortProp_ls[[Sp]] <- train_sp |>
    group_by(iter2) |>
    summarise(
      mortProp_obs = sum(mort == 1)/n(),
      mortProp_pred = sum(mort_pred == 1)/n()
    ) |>
    bind_cols(species_id = Sp)
}

# save accuracy to be used for model comparison
accur_ls |>
  bind_rows() |>
  saveRDS(file.path('output', simName, 'accuracy.RDS'))
mortProp_ls |>
  bind_rows() |>
  saveRDS(file.path('output', simName, 'mortProp.RDS'))

accur_ls |>
  bind_rows() |>
  select(species_id, iter2, Acc, Sensitivity, Specificity, AccCorrected) |>
  pivot_longer(
    cols = c(Acc, Sensitivity, Specificity, AccCorrected)
  ) |>
  mutate(
    name = recode_factor(
      name,
      Acc = 'Accuracy',
      AccCorrected = 'Accuracy corrected',
      Sensitivity = 'Sensitivity',
      Specificity = 'Specificity'
    )
  ) |>
  ggplot(aes(x = value, y = species_id)) +
    ggridges::geom_density_ridges2(color = NA, alpha = 0.8) +
    facet_wrap(~ name, scales = 'free_x') +
    theme_classic() +
    xlab('') + ylab('')
```


## Proportion of mortality events in the population

```{r plotMortProp,echo=F,warning=FALSE,message=FALSE,fig.height=8,fig.width=7}
propObs <- mortProp_ls |>
  bind_rows() |>
  group_by(species_id) |>
  summarise(mprop = unique(mortProp_obs))

mortProp_ls |>
  bind_rows() |>
  ggplot(aes(x = mortProp_pred, y = species_id)) +
    ggridges::geom_density_ridges2(color = NA, alpha = 0.8) +
    geom_segment(
      data = propObs,
      aes(
        x = mprop, xend = mprop,
        y = 1:length(species_id),
        yend = (1:length(species_id)) + .8
      ),
      color = "red", alpha = 0.6
    ) +
    theme_classic() +
    xlab('Proportion of mortality events (obs in red vs predicted in grey)') +
    ylab('')
```

## Mortality in function of Basal area and climate variables

Not yet...

```{r BApred,echo=FALSE, warning=FALSE, message=FALSE,fig.height = 15, fig.width = 10}
# # get only training data
# train <- trainData[sampled == 'training']

# # compute growth
# train[, growth := (dbh - dbh0)/deltaYear]

# # remove NA
# train <- train[deltaYear > 0]

# # prepare parameters
# post_mean <- post |>
#   filter(
#     par %in% c('r', 'Lmax', 'Beta', 'theta', 'optimal_temp', 'tau_temp', 'optimal_prec', 'tau_prec')
#   ) |>
#   group_by(species_id, par) |>
#   summarise(value_mean = mean(value)) |>
#   pivot_wider(
#     names_from = par,
#     values_from = value_mean
#   ) |>
#   setDT()

# # plot per species_id
# for(Sp in spIds) 
# {
#   train_sp <- train[species_id == Sp]

#   # sample few tree_ids that have at least 2 measures
#   tree_ids <- train_sp[, .N, by = tree_id][N > 2, sample(tree_id, 1000)]
#   train_sp <- train_sp[tree_id %in% tree_ids]

#   # add parameters
#   train_sp[,
#     c('Beta', 'theta', 'Lmax', 'optimal_temp', 'tau_temp', 'optimal_prec', 'tau_prec') := post_mean[
#                       species_id == Sp,
#                       .(Beta, theta, Lmax, optimal_temp, tau_temp, optimal_prec, tau_prec)
#                     ]
#   ]
  
#   train_sp[
#     plotEffect |>
#       filter(species_id == Sp) |>
#       select(-species_id) |>
#       setDT(),
#     r_plot := i.psi_natural_mean,
#     on = 'plot_id'
#   ]

#   train_sp[
#     treeEffect |>
#       filter(species_id == Sp) |>
#       select(-species_id) |>
#       setDT(),
#     `:=`(
#       r_tree = i.psi_natural_mean,
#       r_pop = i.r_pop
#     ),
#     on = 'tree_id'
#   ]

#   # compute BA and temp effect on r
#   train_sp[,
#     r_plotBaTemp := exp(
#       log(r_plot) +
#       log(r_tree) -
#       log(r_pop) +
#       Beta * (BA_comp_sp + theta * BA_comp_intra) +
#       -tau_temp * (bio_01_mean - optimal_temp)^2 +
#       -tau_prec * (bio_12_mean - optimal_prec)^2
#     )
#   ]
  
#   # predict size
#   train_sp[,
#     pred_size := dbh0 *
#                 exp(-r_plotBaTemp * deltaYear) +
#                 Lmax * (1 -exp(-r_plotBaTemp * deltaYear))
#   ]

#   # compute growth from predicted size
#   train_sp[, pred_growth := (pred_size - dbh0)/deltaYear]

#   # compute observed and predicted relative growth
#   train_sp[, obs_relativeGrowth := growth/dbh0]
#   train_sp[, pred_relativeGrowth := pred_growth/dbh0]

#   # define ylim to remove outliers
#   yLim <- train_sp[, quantile(growth, probs = c(0.001, .999))]
#   yLim_rel <- train_sp[, quantile(obs_relativeGrowth, probs = c(0.001, 0.999))]

#   # species parameters
#   post_sp <- post_mean |> 
#         filter(species_id == Sp)

#   # define intercept of effect functions
#   # Formula: Lmax  * (1 - r)
#   Int <- post_sp$Lmax * (1 - exp(-exp(post_sp$r)))

#   # update ylim if Intercept if larger than max limit
#   yLim[2] = max(c(Int, yLim[2]))
#   yLim_rel[2] = max(c(Int/train_sp[, min(dbh0, na.rm = T)], yLim_rel[2]))

#   p1 <- train_sp |>
#       filter(!is.na(pred_growth)) |>
#       select(dbh0, obs_relativeGrowth, pred_relativeGrowth) |>
#       pivot_longer(
#         cols = contains('growth'),
#         names_to = 'sim'
#       ) |>
#       ggplot(aes(x = dbh0, y = value, color = sim)) +
#         geom_point(alpha = .5, size = .5) +
#         geom_smooth(method = 'gam') +
#         xlab('Size (t0)') +
#         ylab('Relative growth') +
#         labs(subtitle = Sp) +
#         theme_minimal() + 
#         ylim(yLim_rel) + 
#         geom_function(
#           fun = function(x)
#             (Int + exp(-exp(post_sp$r)) * x - x)/x,
#           color = 1,
#           linetype = 'dashed'
#         )

#   # define xlim fro BA
#   xLim <- train_sp[, range(c(BA_comp_sp, BA_comp_intra))]
  
#   p2 <- train_sp |>
#       filter(!is.na(pred_growth)) |>
#       mutate(obs_growth = growth) |>
#       select(BA_comp_sp, obs_growth, pred_growth) |>
#       pivot_longer(
#         cols = contains('growth'),
#         names_to = 'sim'
#       ) |>
#       ggplot(aes(x = BA_comp_sp, y = value, color = sim)) +
#         geom_point(alpha = .5, size = .5) +
#         geom_smooth(method = 'gam') +
#         xlab('Conspecific basal area') +
#         ylab('Growth') +
#         labs(subtitle = '') +
#         theme_minimal() +
#         ylim(yLim) + 
#         xlim(xLim) +
#         geom_function(
#           fun = function(x)
#             Int * exp(x * post_mean |> filter(species_id == Sp) |> pull(Beta)),
#           color = 1,
#           linetype = 'dashed'
#         )

#   p3 <- train_sp |>
#       filter(!is.na(pred_growth)) |>
#       mutate(obs_growth = growth) |>
#       select(BA_comp_intra, obs_growth, pred_growth) |>
#       pivot_longer(
#         cols = contains('growth'),
#         names_to = 'sim'
#       ) |>
#       ggplot(aes(x = BA_comp_intra, y = value, color = sim)) +
#         geom_point(alpha = .5, size = .5) +
#         geom_smooth(method = 'gam') +
#         xlab('Heterospecific basal area') +
#         ylab('Growth') +
#         labs(subtitle = '') +
#         theme_minimal() +
#         ylim(yLim) + 
#         xlim(xLim) +
#         geom_function(
#           fun = function(x)
#             Int * exp(x * post_mean |> filter(species_id == Sp) |> mutate(betaTheta = Beta * theta) |> pull(betaTheta)),
#           color = 1,
#           linetype = 'dashed'
#         )


#   p4 <- train_sp |>
#       filter(!is.na(pred_growth)) |>
#       mutate(obs_growth = growth) |>
#       select(bio_01_mean, obs_growth, pred_growth) |>
#       pivot_longer(
#         cols = contains('growth'),
#         names_to = 'sim'
#       ) |>
#       ggplot(aes(x = bio_01_mean, y = value, color = sim)) +
#         geom_point(alpha = .5, size = .5) +
#         geom_smooth(method = 'gam') +
#         xlab('Mean annual temperature') +
#         ylab('Growth') +
#         labs(subtitle = '') +
#         theme_minimal() +
#         ylim(yLim) +
#         geom_function(
#           fun = function(x) Int * exp(
#             -(post_mean |> filter(species_id == Sp) |> pull(tau_temp)) *
#             (x - post_mean |> filter(species_id == Sp) |> pull(optimal_temp))^2
#           ),
#           col = 1,
#           linetype = 'dashed'
#         )

#   p5 <- train_sp |>
#       filter(!is.na(pred_growth)) |>
#       mutate(obs_growth = growth) |>
#       select(bio_12_mean, obs_growth, pred_growth) |>
#       pivot_longer(
#         cols = contains('growth'),
#         names_to = 'sim'
#       ) |>
#       ggplot(aes(x = bio_12_mean, y = value, color = sim)) +
#         geom_point(alpha = .5, size = .5) +
#         geom_smooth(method = 'gam') +
#         xlab('Mean annual precipitation') +
#         ylab('Growth') +
#         labs(subtitle = '') +
#         theme_minimal() +
#         ylim(yLim) +
#         geom_function(
#           fun = function(x) Int * exp(
#             -(post_mean |> filter(species_id == Sp) |> pull(tau_prec)) *
#             (x - post_mean |> filter(species_id == Sp) |> pull(optimal_prec))^2
#           ),
#           col = 1,
#           linetype = 'dashed'
#         )

#   print(
#     ggpubr::ggarrange(
#       p2, p3, p1, p4, p5,
#       ncol = 2, nrow = 3, legend = 'top', common.legend = TRUE)
#   )
# }
```


# Out-of-bag cross-validation

```{r obbCrossValidation, echo=FALSE, warning=FALSE, message=FALSE, fig.height = 9, fig.width = 9}
# As we are using each draw of the posterior distribution to predict the validation data, the dataset becames too big to store all species in memory.
# So I will loop over each species to (i) load dataset, (ii) predict for validation, (iii) compute prediction metrics and (iv) generate the plots

# list accuracy db for each species
accurOBB_ls <- mortPropOBB_ls <- list()

# some species did not have enough data for spliting train and validation
# run only for species with validation data
spIds_val <- trainData[sampled == 'validation', unique(species_id)]
for(Sp in spIds_val)
{
  val_sp <- trainData[species_id == Sp & sampled == 'validation']

  # replicate each observation by N_iteration to accommodate the parameters draw
  # Using only 300 iterations of the 8000 to speed calculation as the final
  # result is quite similar to use the 8000 iteractions
  val_sp[, obsID := .I]
  val_sp <- val_sp[rep(obsID, each = 300)]
  sampledIter <- sample(1:(simInfo$maxIter/2 * simInfo$nC), 300)
  val_sp[, iter := sampledIter, by = obsID]

  # merge global parameters
  val_sp[
    post |>
        filter(species_id == Sp) |>
        select(-species_id) |>
        pivot_wider(names_from = par, values_from = value) |>
        setDT(),
    `:=`(
      psi = i.psi,
      sigma_plot = i.sigma_plot
    ),
    on = 'iter'
  ]
  
  # merge plot_id parameters if plot is present in validation data
  val_sp[
    readRDS(posteriorrPlot_files[Sp]) |>
      mutate(
        plot_id_seq = parse_number(par)
      ) |>
      select(!par) |>
      setDT(),
    psiPlot := i.value,
    on = c('iter', 'plot_id_seq')
  ]

  # for the plots not used in the fit model, generate the rPlot_log
  # value from the population distribution
  val_sp[
    is.na(plot_id_seq),
    psiPlot := rnorm(.N, 0, sigma_plot)
  ]

  # random iter were selected, create a new iter vetor to a proprer sequence
  # from 1 to nSample of iteration
  val_sp[, iter2 := 1:.N, by = obsID]

  # compute longevity logit
  val_sp[,
    longev_log := 1/(1 + exp(
        -psi + 
        psiPlot
      )
    )
  ]

  # compute mortality rate in function of time
  val_sp[,
    mortality_prob := 1 - (longev_log^deltaYear)
  ]

  # predict mortality event
  val_sp[,
    mort_pred := rbinom(.N, size = 1, mortality_prob)
  ]

  # Compute model accuracy
  accurOBB_ls[[Sp]] <- val_sp |>
    group_by(iter2) |>
    summarise(
      TP = sum(mort == 1 & mort_pred == 1),
      TN = sum(mort == 0 & mort_pred == 0),
      FN = sum(mort == 1 & mort_pred == 0),
      FP = sum(mort == 0 & mort_pred == 1)
    ) |>
    mutate(
      Acc = (TP + TN)/(TP + TN + FP + FN),
      Sensitivity = TP/(TP + FN),
      Specificity = TN/(FP + TN),
      AccCorrected = (Sensitivity + Specificity)/2
    ) |>
    bind_cols(species_id = Sp)

  # Compute proportion of mortality events (pred vs obs)
  mortPropOBB_ls[[Sp]] <- val_sp |>
    group_by(iter2) |>
    summarise(
      mortProp_obs = sum(mort == 1)/n(),
      mortProp_pred = sum(mort_pred == 1)/n()
    ) |>
    bind_cols(species_id = Sp)
}

# save accuracy to be used for model comparison
accurOBB_ls |>
  bind_rows() |>
  saveRDS(file.path('output', simName, 'accuracy_oob.RDS'))
mortPropOBB_ls |>
  bind_rows() |>
  saveRDS(file.path('output', simName, 'mortProp_oob.RDS'))  
```

```{r plot_accurOOB, echo = FALSE, warning=FALSE, message=FALSE, fig.height = 12, fig.width = 9}
accurOBB_ls |>
  bind_rows() |>
  select(species_id, iter2, Acc, Sensitivity, Specificity, AccCorrected) |>
  pivot_longer(
    cols = c(Acc, Sensitivity, Specificity, AccCorrected)
  ) |>
  mutate(
    name = recode_factor(
      name,
      Acc = 'Accuracy',
      AccCorrected = 'Accuracy corrected',
      Sensitivity = 'Sensitivity',
      Specificity = 'Specificity'
    )
  ) |>
  ggplot(aes(x = value, y = species_id)) +
    ggridges::geom_density_ridges2(color = NA, alpha = 0.8) +
    facet_wrap(~ name, scales = 'free_x') +
    theme_classic() +
    xlab('') + ylab('')
```


## OOB proportion of mortality events in the population

```{r plotMortPropOBB,echo=F,warning=FALSE,message=FALSE,fig.height=8,fig.width=7}
propObs <- mortPropOBB_ls |>
  bind_rows() |>
  group_by(species_id) |>
  summarise(mprop = unique(mortProp_obs))

mortPropOBB_ls |>
  bind_rows() |>
  ggplot(aes(x = mortProp_pred, y = species_id)) +
    ggridges::geom_density_ridges2(color = NA, alpha = 0.8) +
    geom_segment(
      data = propObs,
      aes(
        x = mprop, xend = mprop,
        y = 1:length(species_id),
        yend = (1:length(species_id)) + .8
      ),
      color = "red", alpha = 0.6
    ) +
    theme_classic() +
    xlab('Proportion of mortality events (obs in red vs predicted in grey)') +
    ylab('')
```

# Leave-one-out cross-validation to compare models

Not yet...

```{r loo, echo = FALSE, warning=FALSE,fig.height = 8, fig.width = 8, warning=FALSE, message=FALSE}

# sim_toLoad <- c(simInfo$simCompare, simName)

# map_dfr(
#     spIds,
#     ~ map2(
#         setNames(sim_toLoad, sim_toLoad),
#         .x,
#         ~ readRDS(paste0('output/', .x, '/loo_', .y, '.RDS'))
#       ) |>
#       loo::loo_compare() |>
#       as.data.frame() |>
#       bind_cols(species_id = .x) |>
#       rownames_to_column(var = 'sim')
#   ) |>
#   select(species_id, sim, elpd_diff, se_diff) |>
#   pivot_longer(
#     cols = c(elpd_diff, se_diff),
#     names_to = 'variable',
#     values_to = 'value'
#   ) |>
#   ggplot(aes(x = value, y = species_id, color = sim)) +
#     geom_point() +
#     facet_wrap(~ variable, scales = 'free_x') +
#     xlab('') + ylab('') +
#     theme_bw() +
#     theme(legend.position = 'bottom')
```

```{r loo2, echo = FALSE, warning=FALSE,fig.height = 4, fig.width = 8, warning=FALSE, message=FALSE}
# map_dfr(
#     spIds,
#     ~ map2(
#         setNames(sim_toLoad, sim_toLoad),
#         .x,
#         ~ readRDS(paste0('output/', .x, '/loo_', .y, '.RDS'))
#       ) |>
#       loo::loo_compare() |>
#       as.data.frame() |>
#       bind_cols(species_id = .x) |>
#       rownames_to_column(var = 'sim')
#   ) |>
#   select(species_id, sim, elpd_diff, se_diff) |>
#   pivot_longer(
#     cols = contains('diff')
#   ) |>
#   ggplot(aes(y = sim, x = value)) +
#     geom_boxplot() +
#     facet_wrap(~name) +
#     theme_bw()
```


# Sampling time

```{r plot sampling time, echo = FALSE, fig.height = 7, fig.width = 8}
map2_dfr(
  diag_files,
  names(diag_files),
  ~ readRDS(.x)[['time']][['chains']] |>
    bind_cols(species_id = .y)
) |>
ggplot(aes(x = total/3600, y = species_id)) +
  geom_boxplot() +
  xlab('Fit time (hours)') +
  theme_minimal()
```

---
 title: "MCMC diagnostics - Growth"
 subtitle: "Test v12.0 - Von Bertalanffy model - using parametric start_size with measurement error"
 author: "Will Vieira"
 date: "`r paste('Last updated on', format(Sys.time(), '%d %B, %Y'))`"
---


## Diagnostics for the Von Bertalanffy model

```{r, echo = F, message=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(data.table))
suppressPackageStartupMessages(library(cmdstanr))
suppressPackageStartupMessages(library(loo))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(purrr))
suppressPackageStartupMessages(library(ggpubr))
suppressPackageStartupMessages(library(tidybayes))
suppressPackageStartupMessages(library(bayesplot))
suppressPackageStartupMessages(library(ggridges))
suppressPackageStartupMessages(require(RColorBrewer))
suppressPackageStartupMessages(library(DT))
```


```{r load simulations, echo = F}
# Load simulation variables
simInfo <- yaml::read_yaml('_simulation_info.yml')

spIds <- simInfo$spIds
simName <- simInfo$simName
simulations <- simInfo$simulations

# List output files and set vector names to species_id
posteriorPop_files <- grep(
  'posteriorPop',
  dir(file.path('output', simName), full.names = TRUE),
  value = TRUE
)
names(posteriorPop_files) <- names(sort(sapply(spIds, function(x) grep(x, posteriorPop_files))))

posteriorLo_files <- grep(
  'posteriorLo',
  dir(file.path('output', simName), full.names = TRUE),
  value = TRUE
)
names(posteriorLo_files) <- names(sort(sapply(spIds, function(x) grep(x, posteriorLo_files))))

diag_files <- grep(
  'diagnostics',
  dir(file.path('output', simName), full.names = TRUE),
  value = TRUE
)
names(diag_files) <- names(sort(sapply(spIds, function(x) grep(x, diag_files))))

trainData_files <- grep(
  'trainData',
  dir(file.path('output', simName), full.names = TRUE),
  value = TRUE
)
names(trainData_files) <- names(sort(sapply(spIds, function(x) grep(x, trainData_files))))
```

```{r load dataset,echo =FALSE}
trainData <- map2_dfr(
  trainData_files,
  names(trainData_files),
  ~ readRDS(.x)
)

treeData <- readRDS('data/treeData.RDS')
treeData <- treeData[species_id %in% spIds]

# calculate time since first measurement
treeData[,
  time := year_measured - year_measured[which.min(year_measured)],
  by = tree_id
]

# calculate start_size for each tree_id
treeData[,
  start_size := dbh[which(time == 0)], by = tree_id
]

# merge with train data
treeData[
  trainData,
  sampled := i.sampled,
  on = c('tree_id', 'year_measured')
]

# add species_id to trainData
trainData[
  treeData,
  `:=`(
    'species_id' = i.species_id,
    'dbh' = i.dbh,
    'time' = i.time,
    'start_size' = i.start_size
  ),
  on = c('tree_id', 'year_measured')
]
```

# Rhat

```{r rhat, echo = F, fig.height = 7, fig.width = 7}
map2_dfr(
  diag_files,
  names(diag_files),
  ~ readRDS(.x)[['rhat']] |>
      bind_cols(species_id = .y)
) |>
ggplot(aes(x = rhat, y = species_id)) +
  geom_boxplot()
```



# Divergent transitions

```{r divergentTransitions, echo = FALSE}
map2_dfr(
  diag_files,
  names(diag_files),
  ~ readRDS(.x)[['diag_summary']]['num_divergent'] |>
      bind_cols(species_id = .y) |>
      mutate(chain = row_number())
) |>
pivot_wider(
  names_from = chain,
  values_from = num_divergent,
  names_prefix = 'chain '
) |>
DT::datatable()
```



# Posterior distribution of parameters

```{r posteriorDist, eval = TRUE,echo = F, fig.height = 7, fig.width = 8}
post <- map2_dfr(
  posteriorPop_files,
  names(posteriorPop_files),
  ~ readRDS(.x) |>
    bind_cols(species_id = .y)
)

for(Par in unique(post$par))
{
  print(
    post |>
      filter(par == Par) |>
      ggplot(aes(x = value, y = species_id)) +
        stat_eye() +
        ggtitle(Par) +
        xlab('')
  )
}
```


# Correlation between parameters

```{r parCorrelation, eval = TRUE,echo = F, fig.height = 8, fig.width = 8}

parComb <- post |>
  summarise(uqPar = unique(par)) |>
  pull(uqPar) |>
  combn(2)

for(i in 1:ncol(parComb))
{
  print(
    post |>
      filter(par %in% parComb[, i]) |>
      filter(iter %in% sample(iter, 1000)) |>
      select(par, value, iter, species_id) |>
      pivot_wider(names_from = par, values_from = value) |>
      ggplot(aes_string(x = parComb[1, i], y = parComb[2, i])) + 
          geom_point() +
          facet_wrap(~ species_id) +
          xlab(parComb[1, i]) +
          ylab(parComb[2, i])
  )
}
```


# Correlation between Lo parameter and start size data

```{r posterior_Lo, eval = TRUE,echo = F,warning=FALSE, message=FALSE, fig.height = 4.5, fig.width = 8}
for(Sp in seq(1, 17, 2))
{
  plot_ls <- list()
  for(i in 0:1) {
    if(Sp == 17 & i == 1)
      next
    
    plot_ls[[i+1]] <- readRDS(posteriorLo_files[spIds[Sp + i]]) |>
      mutate(tree_id_seq = parse_number(par)) |>
      left_join(
        trainData[
          species_id == spIds[Sp + i] & !is.na(tree_id_seq),
          .(start_size = unique(start_size)),
          by = tree_id_seq
        ]
      ) |>
      ggplot(aes(start_size, y = value)) +
        geom_hex(bins = 60) +
        geom_abline(intercept = 0, slope = 1) +
        tune::coord_obs_pred() +
        theme(legend.position="none") +
        xlab('Observed start_size (mm)') +
        ylab('Predicted start_size Lo (mm)') +
        ggtitle(spIds[Sp + i])
  }
  print(
    ggpubr::ggarrange(plotlist = plot_ls, ncol = 2)
  )
}
```


# Data distribution

```{r organize data, echo = FALSE, warning=FALSE, message=FALSE, fig.height = 7, fig.width = 8}
# split between train and everything else (merge validate with rest of data)
treeData[, sampled2 := sampled]
treeData[is.na(sampled), sampled2 := 'validation']

treeData[, .(species_id, dbh, time, sampled2)] |>
  mutate(sample = sampled2) |>
  pivot_longer(
    cols = c(dbh, time),
    names_to = 'var'
  ) |>
  ggplot(aes(x = value, y = species_id, fill = sample)) +
    geom_density_ridges(alpha = 0.7, color = NA) +
    facet_wrap(~var, scales = 'free_x') +
    xlab('')
```



# Predictions

```{r,echo=FALSE,fig.height = 6.5, fig.width = 8}
post |>
  filter(par %in% c('r', 'Lmax')) |>
  pivot_wider(
    names_from = par,
    values_from = value
  ) |>
  group_by(species_id) |>
  expand_grid(time = seq(0, 2000, 100)) |>
  mutate(Lt = Lmax * (1 - exp(-r * time))) |>
  ggplot(aes(x = time, y = Lt, color = species_id)) +
        stat_lineribbon(.width = 0.95, alpha = .8) +
        scale_fill_brewer() +
        #theme(legend.position="none") +
        ylab('DBH size (mmm)') + xlab('Time (years)')
```

# Out-of-bag cross-validation

To assess model generality we test how good the model is in predicting new observations. The following figures show a 1:1 plot of observed vs predicted data for two diferent measures: DBH size (directly predicted by the model) and annual growth rate (derived from predicted size). We also plot the distribution of the observed vs the predicted measures.

```{r obbCrossValidation, echo=FALSE, warning=FALSE, message=FALSE, fig.height = 9, fig.width = 9}
# As we are using each draw of the posterior distribution to predict the validation data, the dataset becames too big to store all species in memory.
# So I will loop over each species to (i) load dataset, (ii) predict for validation, (iii) compute prediction metrics and (iv) generate the plots

# list to save MSE and R2 for each species to be used later
MSE_list <- R2_list <- list()

for(Sp in spIds)
{
  val_sp <- trainData[species_id == Sp & sampled == 'validation']

  # replicate each observation by N_iteration to accommodate the parameters draw
  # Using only 1k iterations of the 8000
  val_sp[, obsID := .I]
  val_sp <- val_sp[rep(obsID, each = 1000)]
  sampledIter <- sample(1:(simInfo$maxIter/2 * simInfo$nC), 1000)
  val_sp[, iter := sampledIter, by = obsID]

  # merge global parameters
  val_sp <- merge(
      val_sp,
      post |>
          filter(species_id == Sp) |>
          select(-species_id) |>
          pivot_wider(names_from = par, values_from = value) |>
          as.data.table(),
      by = c('iter')
  )
  
  # random iter were selected, create a new iter vetor to a proprer sequence
  # from 1 to nSample of iteration
  val_sp[, iter2 := 1:.N, by = obsID]

  # predict size
  val_sp[,
    pred_size := rnorm(.N, start_size, sigma_obs) *
                  exp(-r * time) + Lmax * (1 -exp(-r * time))
  ]

  # simulate size from model distribution (normal dist)
  val_sp[, pred_size_random := rnorm(.N, pred_size, sigma_obs)]

  # calculate observed and predicted growth 
  val_sp[, time0 := shift(time, type = 'lag'), by = tree_id]
  val_sp[, obs_size0 := shift(dbh, type = 'lag'), by = tree_id]

  val_sp[, pred_size0 := shift(pred_size, type = 'lag'), by = tree_id]
  val_sp[, pred_size_random0 := shift(pred_size_random, type = 'lag'), by = tree_id]

  val_sp[, obs_growth := (dbh - obs_size0)/(time - time0)]
  val_sp[, pred_growth := (pred_size - pred_size0)/(time - time0)]
  val_sp[, pred_growth_random := (pred_size_random - pred_size_random0)/(time - time0)]

  # calculate MSE
  val_sp[, SE_size := (dbh - pred_size_random)^2]
  val_sp[, SE_growth := (obs_growth - pred_growth_random)^2]

  # mean SE over all observations for each iteration and save to list
  MSE_list[[Sp]] <- val_sp[, 
    .(
      MSE_size = mean(SE_size, na.rm = TRUE),
      MSE_growth = mean(SE_growth, na.rm = TRUE),
      species_id = Sp
    ),
    by = iter2
  ]

  # Calculate R2 (Gelman et al 2018)
  R2gel <- val_sp |>
    group_by(iter2) |>
    summarise(var_size = var(pred_size, na.rm = TRUE)) |>
    bind_cols(iter = sampledIter) |>
    left_join(
      post |>
        filter(species_id == Sp & par == 'sigma_obs') |>
        mutate(sigma_obs = value) |>
        select(iter, sigma_obs, species_id)
    ) |>
    mutate(R2gelman_size = var_size/(var_size + sigma_obs^2)) |>
    select(iter, iter2, species_id, R2gelman_size) |>
    setDT()

  # calculate R2 from regression linear model using the 1:1 obs vs pred
  get_r2 <- function(x, y)
      return(summary(lm(y~x))$r.squared)
  
  R2_list[[Sp]] <- merge(
    R2gel,
    val_sp[,
      .(
        R2reg_size = get_r2(dbh, pred_size_random),
        R2reg_growth = get_r2(obs_growth, pred_growth_random)
      ), 
      by = iter2
    ],
    by = 'iter2'
  )

  # plot
  p1 <- val_sp[time > 0, .(m_obs = mean(dbh), m_pred = mean(pred_size)), by = obsID] |>
      ggplot(aes(m_obs, m_pred)) +
          geom_hex(bins = 100) +
          geom_abline(slope = 1, intercept = 0) + 
          tune::coord_obs_pred() +
          theme(
                legend.position="none",
                plot.margin = margin(t = 30)
            ) +
          xlab('Observerd size') +
          ylab('Predicted size')

  p2 <- val_sp[time > 0, .(m_obs = mean(obs_growth), m_pred = mean(pred_growth)), by = obsID]  |>
      ggplot(aes(m_obs, m_pred)) +
          geom_hex(bins = 100) +
          geom_abline(slope = 1, intercept = 0) +
          xlim(-3, 20) + ylim(-3, 20) +
          theme(
                legend.position="none",
                plot.margin = margin(t = 30)
            ) +
          xlab('Observerd growth') +
          ylab('Predicted growth')

  pred_size_matrix <- val_sp[time > 0 & !is.na(pred_size_random), .(pred_size_random, iter2, obsID)] |>
      pivot_wider(names_from = obsID, values_from = pred_size_random) |>
      select(-iter2) |>
      as.matrix()

  p3 <- ppc_dens_overlay(
      val_sp[iter2 == 1 & time > 0, dbh],
      pred_size_matrix
  )

  pred_growth_matrix <- val_sp[time > 0 & !is.na(pred_growth), .(pred_growth_random, iter2, obsID)] |>
      pivot_wider(names_from = obsID, values_from = pred_growth_random) |>
      select(-iter2) |>
      as.matrix()

  p4 <- ppc_dens_overlay(
      val_sp[iter2 == 1 & time > 0, obs_growth],
      pred_growth_matrix
  )

  print(
    ggpubr::ggarrange(
        p1, p2, p3, p4,
        ncol = 2, nrow = 2,
        labels = Sp,
        font.label = list(size = 9, face = 'bold')
    )
  )
}

# save MSE and R2 to be used for model comparison
invisible(
    map_dfr(
    c('MSE', 'R2'),
    ~ get(paste0(.x, '_list')) |>
        bind_rows() |>
        saveRDS(file = file.path(
          'output', 
          simName,
          paste0(.x, '.RDS')
      )
    )
  )
)
```


# Mean squared error (MSE) of out-of-bag predictions

```{r plot_MSE, echo = FALSE, warning=FALSE, message=FALSE, fig.height = 7, fig.width = 8}
sim_toLoad <- c(simInfo$simCompare, simName)

  map_dfr(
    sim_toLoad,
    ~ readRDS(file.path('output', .x, 'MSE.RDS')) |>
      bind_cols(sim = .x)
  ) |>
  mutate(
    `Predicted size` = MSE_size,
    `Predicted growth` = MSE_growth
  ) |>
  select(-contains('MSE')) |>
  pivot_longer(
    cols = contains('Predicted')
  ) |>
  mutate(name2 = factor(name,  levels = c('Predicted size', 'Predicted growth'))) |>
  ggplot(aes(x = value, y = species_id, fill = sim)) +
    geom_density_ridges(alpha = 0.8, scale= 1.8, color = NA) +
    facet_wrap(~name2, scales = 'free_x') +
    xlab('Mean Squared error (MSE)') + ylab('')
```


# Rsquared

The distribution of R squared values is calculated using the Gelman et al. [2018](http://www.stat.columbia.edu/~gelman/research/unpublished/bayes_R2.pdf) definition.

```{r plot Rsquared_gelman,echo=FALSE,fig.height = 7.5, fig.width = 8, warning=FALSE, message=FALSE}
map_dfr(
    sim_toLoad,
    ~ readRDS(file.path('output', .x, 'R2.RDS')) |>
      bind_cols(sim = .x)
  ) |>
  ggplot(aes(x = R2gelman_size, y = species_id, fill = sim)) +
      geom_density_ridges(alpha = 0.8, scale= 1.8, color = NA) +
      xlab('Rsquared (Gelman 2018)')
```

We also calculated the $R^2$ from the linear model using the 1:1 plot comparing observed values to the predicted values. This approach was used for the size predictions from the model, and the growth predictions derived from the size predictions.

```{r plot Rsquared_regression,echo=FALSE,fig.height = 6, fig.width = 8, warning=FALSE, message=FALSE}
map_dfr(
    sim_toLoad,
    ~ readRDS(file.path('output', .x, 'R2.RDS')) |>
      bind_cols(sim = .x)
  ) |>
  mutate(
    `R2 predicted size` = R2reg_size,
    `R2 predicted growth` = R2reg_growth
  ) |>
  select(species_id, iter2, sim, contains('R2 predicted')) |>
  pivot_longer(
    cols = contains('R2 predicted'),
    names_to = 'par',
    values_to = 'value'
  ) |>
  mutate(
    par2 = factor(par,  levels = c('R2 predicted size', 'R2 predicted growth'))
  ) |>
  ggplot(aes(x = value, y = species_id, fill = sim)) +
    geom_density_ridges(alpha = 0.8, scale= 1.8, color = NA) +
    facet_wrap(~par2, scales = 'free_x') +
    xlab('Rsquared (linear regression)')
```

# Leave-one-out cross-validation to compare models

```{r loo, echo = FALSE, warning=FALSE,fig.height = 7, fig.width = 8, warning=FALSE, message=FALSE}
map_dfr(
    spIds,
    ~ map2(
        setNames(sim_toLoad, sim_toLoad),
        .x,
        ~ readRDS(paste0('output/', .x, '/loo_', .y, '.RDS'))
      ) |>
      loo::loo_compare() |>
      as.data.frame() |>
      bind_cols(species_id = .x) |>
      rownames_to_column(var = 'sim')
  ) |>
  select(species_id, sim, elpd_diff, se_diff) |>
  pivot_longer(
    cols = c(elpd_diff, se_diff),
    names_to = 'variable',
    values_to = 'value'
  ) |>
  ggplot(aes(x = value, y = species_id, color = sim)) +
    geom_point() +
    facet_wrap(~ variable, scales = 'free_x') +
    xlab('') + ylab('')

```


# Sampling time

```{r plot sampling time, echo = FALSE, fig.height = 7, fig.width = 8}
map2_dfr(
  diag_files,
  names(diag_files),
  ~ readRDS(.x)[['time']][['chains']] |>
    bind_cols(species_id = .y)
) |>
ggplot(aes(x = total/3600, y = species_id)) +
  geom_boxplot() +
  xlab('Fit time (hours)')
```

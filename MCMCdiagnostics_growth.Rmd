---
 title: "MCMC diagnostics - Growth"
 subtitle: "Test v16.0 - Von Bertalanffy model - r in function of BA_comp. Using previous measure as S_t instead of using the first measurement of the individual"
 author: "Will Vieira"
 date: "`r paste('Last updated on', format(Sys.time(), '%d %B, %Y'))`"
---


## Diagnostics for the Von Bertalanffy model

```{r, echo = F, message=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(data.table))
suppressPackageStartupMessages(library(cmdstanr))
suppressPackageStartupMessages(library(loo))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(purrr))
suppressPackageStartupMessages(library(ggpubr))
suppressPackageStartupMessages(library(tidybayes))
suppressPackageStartupMessages(library(bayesplot))
suppressPackageStartupMessages(library(ggridges))
suppressPackageStartupMessages(require(RColorBrewer))
suppressPackageStartupMessages(library(DT))
```


```{r load simulations, echo = F}
# Load simulation variables
simInfo <- yaml::read_yaml('_simulation_info.yml')

spIds <- simInfo$spIds
simName <- simInfo$simName
simulations <- simInfo$simulations

# List output files and set vector names to species_id
posteriorPop_files <- grep(
  'posteriorPop',
  dir(file.path('output', simName), full.names = TRUE),
  value = TRUE
)
names(posteriorPop_files) <- names(sort(sapply(spIds, function(x) grep(x, posteriorPop_files))))

posteriorrPlot_files <- grep(
  'posteriorrPlot',
  dir(file.path('output', simName), full.names = TRUE),
  value = TRUE
)
names(posteriorrPlot_files) <- names(sort(sapply(spIds, function(x) grep(x, posteriorrPlot_files))))

diag_files <- grep(
  'diagnostics',
  dir(file.path('output', simName), full.names = TRUE),
  value = TRUE
)
names(diag_files) <- names(sort(sapply(spIds, function(x) grep(x, diag_files))))

trainData_files <- grep(
  'trainData',
  dir(file.path('output', simName), full.names = TRUE),
  value = TRUE
)
names(trainData_files) <- names(sort(sapply(spIds, function(x) grep(x, trainData_files))))
```

```{r load dataset,echo =FALSE}
trainData <- map2_dfr(
  trainData_files,
  names(trainData_files),
  ~ readRDS(.x)
)

treeData <- readRDS('data/treeData.RDS')
treeData <- treeData[species_id %in% spIds]

## compute de deltaTime between measures of dbh
treeData[,
  deltaTime := year_measured - lag(year_measured, 1),
  by = tree_id
]

## define previous measure
treeData[,
  dbh0 := lag(dbh, 1),
  by = tree_id
]

## Fill the NA first measures with their non lag information
treeData[is.na(deltaTime), deltaTime := 0]
treeData[deltaTime == 0, dbh0 := dbh]


# merge with train data
treeData[
  trainData,
  sampled := i.sampled,
  on = c('tree_id', 'year_measured')
]

# add species_id to trainData
trainData[
  treeData,
  `:=`(
    'plot_id' = i.plot_id,
    'species_id' = i.species_id,
    'dbh' = i.dbh,
    'deltaTime' = i.deltaTime,
    'dbh0' = i.dbh0,
    'BA_comp' = i.BA_comp
  ),
  on = c('tree_id', 'year_measured')
]

```

# Rhat

```{r rhat, echo = F, fig.height = 7, fig.width = 7}
map2_dfr(
  diag_files,
  names(diag_files),
  ~ readRDS(.x)[['rhat']] |>
      bind_cols(species_id = .y)
) |>
ggplot(aes(x = rhat, y = species_id)) +
  geom_boxplot() +
  theme_minimal()
```



# Divergent transitions

```{r divergentTransitions, echo = FALSE}
map2_dfr(
  diag_files,
  names(diag_files),
  ~ readRDS(.x)[['diag_summary']]['num_divergent'] |>
      bind_cols(species_id = .y) |>
      mutate(chain = row_number())
) |>
pivot_wider(
  names_from = chain,
  values_from = num_divergent,
  names_prefix = 'chain '
) |>
DT::datatable()
```



# Posterior distribution of parameters

```{r posteriorDist, eval = TRUE,echo = F, fig.height = 7, fig.width = 8}
post <- map2_dfr(
  posteriorPop_files,
  names(posteriorPop_files),
  ~ readRDS(.x) |>
    bind_cols(species_id = .y)
)

for(Par in unique(post$par))
{
  print(
    post |>
      filter(par == Par) |>
      ggplot(aes(x = value, y = species_id)) +
        stat_eye() +
        ggtitle(Par) +
        xlab('') +
        theme_minimal()
  )
}
```


# Correlation between parameters

```{r parCorrelation, eval = TRUE,echo = F, fig.height = 8, fig.width = 8}
parComb <- post |>
  summarise(uqPar = unique(par)) |>
  pull(uqPar) |>
  combn(2)

for(i in 1:ncol(parComb))
{
  print(
    post |>
      filter(par %in% parComb[, i]) |>
      filter(iter %in% sample(iter, 1000)) |>
      select(par, value, iter, species_id) |>
      pivot_wider(names_from = par, values_from = value) |>
      ggplot(aes_string(x = parComb[1, i], y = parComb[2, i])) + 
          geom_point() +
          facet_wrap(~ species_id) +
          xlab(parComb[1, i]) +
          ylab(parComb[2, i]) +
          theme_minimal()
  )
}
```


# Plot random effect

```{r plot_randomEffect, eval = TRUE, warning=FALSE, message=FALSE,echo = F, fig.height = 8, fig.width = 8}
plotEffect_ls <- list()
for(Sp in spIds)
{
    r_pop <- post |>
        filter(species_id == Sp & par == 'r') |>
        mutate(r_pop = value) |>
        select(r_pop, iter)

    r_mean <- r_pop |>
        summarise(r_mean = mean(exp(r_pop))) |>
        pull(r_mean)

    dt_toPlot <- readRDS(posteriorrPlot_files[Sp]) |>
            mutate(plot_id_seq = parse_number(par)) |>
            left_join(
              r_pop
            ) |>
            mutate(r_real = exp(value + r_pop)) |>
            left_join(
              trainData[
                species_id == Sp & !is.na(plot_id_seq),
                .(plot_id = unique(plot_id)),
                by = plot_id_seq
              ]
            ) |>
            left_join(
              treeData[, 
                .(
                  latitude = unique(latitude),
                  BA_plot = mean(BA_plot),
                  bio_01_mean = mean(bio_01_mean),
                  bio_12_mean = mean(bio_12_mean)
                ), 
                by = plot_id 
              ]
            )

      # save plot effect mean to plot against other variables
      # in the next code block
      plotEffect_ls[[Sp]] <- dt_toPlot |>
          group_by(par) |>
          mutate(
            m_rReal = mean(r_real),
            r_pop = exp(r_pop)
          ) |>
          ungroup() |>
          filter(iter == 1) |>
          select(
            plot_id, plot_id_seq, r_pop, m_rReal, latitude,
            BA_plot, bio_01_mean, bio_12_mean
          )
      
      # filter to remove some plots so figure is liseable
      dt_toPlot <- dt_toPlot |>
          filter(plot_id_seq %in% sample(plot_id_seq, 1000)) |>
          mutate(plot_id = fct_reorder(plot_id, latitude))
  
    print(
      ggarrange(
          dt_toPlot |>
              ggplot(aes(y = plot_id, x = r_real, color = bio_01_mean)) +
                stat_pointinterval(alpha = .7, size = .1) +
                geom_vline(
                  xintercept = r_mean, color = 'red', alpha = .8
                ) +
                xlab('r') + ylab('plot_id (ordered by latitude)') +
                theme(
                  legend.position = 'top',
                  axis.text.y = element_blank()
                ) +
                labs(subtitle = Sp),
          dt_toPlot |>
              ggplot(aes(y = plot_id, x = r_real, color = BA_plot)) +
                stat_pointinterval(alpha = .7, size = .1) +
                geom_vline(
                  xintercept = r_mean, color = 'red', alpha = .8
                ) +
                xlab('r') + ylab('') +
                theme(
                  legend.position = 'top',
                  axis.text.y = element_blank()
                ) +
                labs(subtitle = ''),
          ncol = 2
      )
    )
}
```


## Plot random effect in function of annual mean temperature and basal area

```{r plot_randomEffect2, eval = TRUE, warning=FALSE, message=FALSE,echo = F, fig.height = 8, fig.width = 12}
# merge list of sepecies
plotEffect <- plotEffect_ls |>
  bind_rows(.id = 'species_id')

r_pop <- plotEffect |>
  group_by(species_id) |>
  summarise(r = unique(r_pop))

print(
  plotEffect |>
    ggplot(aes(x = bio_01_mean, m_rReal, color = BA_plot)) +
        geom_point(size = 0.6) +
        facet_wrap(~species_id, scales = 'free') +
        geom_hline(data = r_pop, aes(yintercept = r), color = 'red') +
        xlab('Annual mean temperature') +
        ylab('Plot random effect') +
        theme_minimal()
)

print(
  plotEffect |>
    ggplot(aes(x = BA_plot, m_rReal, color = bio_01_mean)) +
        geom_point(size = 0.6) +
        facet_wrap(~species_id, scales = 'free') +
        geom_hline(data = r_pop, aes(yintercept = r), color = 'red') +
        xlab('Plot basal area') +
        ylab('Plot random effect') +
        theme_minimal()
)

print(
  plotEffect |>
    ggplot(aes(x = bio_12_mean, m_rReal, color = BA_plot)) +
        geom_point(size = 0.6) +
        facet_wrap(~species_id, scales = 'free') +
        geom_hline(data = r_pop, aes(yintercept = r), color = 'red') +
        xlab('Total annual precipitation') +
        ylab('Plot random effect') +
        theme_minimal()
)

# save plot effect ot be used against future models
plotEffect |>
  select(species_id, plot_id, m_rReal) |>
  saveRDS(
    file.path(
        'output', 
        simName,
        'meanPlotEffect_rReal.RDS'
    )
  )
```


# Changes in plot random effect from past models

Compare plot random effect with last model to check how variance is changing. 

```{r compare_rReal, echo = FALSE, warning=FALSE, message=FALSE, fig.height = 8, fig.width = 12}
sim_to_compare <- simInfo$simCompare

for(Sim in sim_to_compare)
{
  sim_toLoad <- c(Sim, simName)
    
  print(
    map_dfr(
      sim_toLoad,
      ~ readRDS(file.path('output', .x, 'meanPlotEffect_rReal.RDS')) |>
        bind_cols(sim = .x)
    ) |>
    pivot_wider(
      names_from = sim,
      values_from = m_rReal
    ) |>
    ggplot(aes(x = !!sym(sim_toLoad[1]), y = !!sym(sim_toLoad[2]))) +
      geom_point(size = 0.8, alpha = .7) +
      geom_abline(intercept = 0, slope = 1) +
      #tune::coord_obs_pred() +
      facet_wrap(~species_id, scales = 'free') +
      theme_minimal()
  )
}
```


# Data distribution

```{r organize data, echo = FALSE, warning=FALSE, message=FALSE, fig.height = 7, fig.width = 8}
# split between train and everything else (merge validate with rest of data)
treeData[, sampled2 := sampled]
treeData[is.na(sampled), sampled2 := 'validation']

treeData[, .(species_id, dbh, deltaTime, sampled2)] |>
  mutate(sample = sampled2) |>
  pivot_longer(
    cols = c(dbh, deltaTime),
    names_to = 'var'
  ) |>
  ggplot(aes(x = value, y = species_id, fill = sample)) +
    geom_density_ridges(alpha = 0.7, color = NA) +
    facet_wrap(~var, scales = 'free_x') +
    xlab('') +
    theme_minimal()
```



# Predictions

## Size in function of time

```{r sizePred,echo=FALSE,fig.height = 6.5, fig.width = 8}
post |>
  filter(par %in% c('r', 'Lmax')) |>
  pivot_wider(
    names_from = par,
    values_from = value
  ) |>
  group_by(species_id) |>
  expand_grid(time = seq(0, 2000, 100)) |>
  mutate(Lt = Lmax * (1 - exp(-exp(r) * time))) |>
  ggplot(aes(x = time, y = Lt, color = species_id)) +
        stat_lineribbon(.width = 0.95, alpha = .8) +
        scale_fill_brewer() +
        ylab('DBH size (mmm)') + xlab('Time (years)') +
        theme_minimal()
```

## Basal area effect

```{r sizePred2,echo=FALSE,fig.height = 8, fig.width = 10}
post |>
  filter(par %in% c('r', 'beta')) |>
  pivot_wider(
    names_from = par,
    values_from = value
  ) |>
  group_by(species_id) |>
  expand_grid(BA_comp = seq(0, 120, 5)) |>
  mutate(
    BAeffect = BA_comp * beta,
    r_BA = exp(r + BAeffect)
  ) |>
  select(iter, species_id, BA_comp, BAeffect, r_BA) |>
  pivot_longer(
    cols = c('BAeffect', 'r_BA'),
    names_to = 'sim'
  ) |>
  mutate(
    sim = factor(sim, levels = c('BAeffect', 'r_BA'), labels = c('BA_comp effect on r parameter', 'r parameter'))
  ) |>
  ggplot(aes(x = BA_comp, y = value, color = species_id)) +
    stat_lineribbon(.width = 0.95, alpha = .8) +
    facet_wrap(~sim, scales = 'free') +
    scale_fill_brewer() +
    xlab('Basal area competition') +
    ylab('') +
    theme_minimal() +
    theme(legend.position = 'bottom')

```


## Growth in function of Basal area competition

```{r BApred,echo=FALSE, warning=FALSE, message=FALSE,fig.height = 4.5, fig.width = 9}
# get only training data
train <- trainData[sampled == 'training']

# compute growth
train[, growth := (dbh - dbh0)/deltaTime]

# remove NA
train <- train[deltaTime > 0]

# prepare parameters
post_mean <- post |>
  filter(par %in% c('Lmax', 'beta')) |>
  group_by(species_id, par) |>
  summarise(value_mean = mean(value)) |>
  pivot_wider(
    names_from = par,
    values_from = value_mean
  ) |>
  setDT()

# plot per species_id
for(sp_seq in seq(1, 17, 2)) 
{
  plot_ls <- list()
  for(i in 0:1)
  {
    if(sp_seq == 17 & i == 1)
      next

    Sp <- spIds[sp_seq + i]

    train_sp <- train[species_id == Sp]

    # sample few tree_ids that have at least 2 measures
    tree_ids <- train_sp[, .N, by = tree_id][N > 2, sample(tree_id, 1000)]
    train_sp <- train_sp[tree_id %in% tree_ids]

    # add parameters
    train_sp[, c('beta', 'Lmax') := post_mean[species_id == Sp, .(beta, Lmax)]]
    train_sp[
      plotEffect |>
        filter(species_id == Sp) |>
        select(-species_id) |>
        setDT(),
      r_plot := i.m_rReal,
      on = 'plot_id'
    ]

    # compute BA effect on r
    train_sp[, r_plotBA := exp(log(r_plot) + BA_comp * beta)]
    
    # predict size
    train_sp[,
      pred_size := dbh0 *
                  exp(-r_plotBA * deltaTime) +
                  Lmax * (1 -exp(-r_plotBA * deltaTime))
    ]

    # compute growth from predicted size
    train_sp[, pred_growth := (pred_size - dbh0)/deltaTime]

    # define ylim to remove outliers
    yLim <- train_sp[, quantile(growth, probs = c(0.001, .999))]
    
    plot_ls[[i+1]] <- train_sp |>
        filter(!is.na(pred_growth)) |>
        mutate(obs_growth = growth) |>
        select(BA_comp, obs_growth, pred_growth) |>
        pivot_longer(
          cols = contains('growth'),
          names_to = 'sim'
        ) |>
        ggplot(aes(x = BA_comp, y = value, color = sim)) +
          geom_point(alpha = .5, size = .5) +
          geom_smooth(method = 'lm') +
          xlab('Basal area competition') +
          ylab(ifelse(i == 0, 'Growth', '')) +
          labs(subtitle = Sp) +
          theme_minimal() +
          ylim(yLim)
  }
  print(
    ggpubr::ggarrange(plotlist = plot_ls, ncol = 2, legend = 'right', common.legend = TRUE)
  )
}
```


# Out-of-bag cross-validation

To assess model generality we test how good the model is in predicting new observations. The following figures show a 1:1 plot of observed vs predicted data for two diferent measures: DBH size (directly predicted by the model) and annual growth rate (derived from predicted size). We also plot the distribution of the observed vs the predicted measures.

```{r obbCrossValidation, echo=FALSE, warning=FALSE, message=FALSE, fig.height = 9, fig.width = 9}
# As we are using each draw of the posterior distribution to predict the validation data, the dataset becames too big to store all species in memory.
# So I will loop over each species to (i) load dataset, (ii) predict for validation, (iii) compute prediction metrics and (iv) generate the plots

# list to save MSE and R2 for each species to be used later
MSE_list <- R2_list <- list()

for(Sp in spIds)
{
  val_sp <- trainData[species_id == Sp & sampled == 'validation']

  # replicate each observation by N_iteration to accommodate the parameters draw
  # Using only 300 iterations of the 8000 to speed calculation as the final
  # result is quite similar to use the 8000 iteractions
  val_sp[, obsID := .I]
  val_sp <- val_sp[rep(obsID, each = 200)]
  sampledIter <- sample(1:(simInfo$maxIter/2 * simInfo$nC), 200)
  val_sp[, iter := sampledIter, by = obsID]

  # merge global parameters
  val_sp[
    post |>
        filter(species_id == Sp) |>
        select(-species_id) |>
        pivot_wider(names_from = par, values_from = value) |>
        as.data.table(),
    `:=`(
      r = i.r,
      sigma_plot = i.sigma_plot,
      sigma_obs = i.sigma_obs,
      Lmax = i.Lmax,
      beta = i.beta
    ),
    on = 'iter'
  ]
  
  # merge plot_id parameters if plot is present in validation data
  val_sp[
    readRDS(posteriorrPlot_files[Sp]) |>
      mutate(
        plot_id_seq = parse_number(par),
        rPlot_log = value
      ) |>
      select(iter, plot_id_seq, rPlot_log) |>
      setDT(),
    rPlot_log := i.rPlot_log,
    on = c('iter', 'plot_id_seq')
  ]

  # for the plots not used in the fit model, generate the rPlot_log
  # value from the population distribution
  val_sp[
    is.na(plot_id_seq),
    rPlot_log := rnorm(.N, 0, sigma_plot)
  ]

  # random iter were selected, create a new iter vetor to a proprer sequence
  # from 1 to nSample of iteration
  val_sp[, iter2 := 1:.N, by = obsID]

  # compute r plot specific parameter
  val_sp[,
    r_plot := exp(r + rPlot_log + BA_comp * beta)
  ]

  # predict size
  val_sp[,
    pred_size := dbh0 *
                  exp(-r_plot * deltaTime) +
                  Lmax * (1 -exp(-r_plot * deltaTime))
  ]

  # simulate size from model distribution (normal dist)
  val_sp[, pred_size_random := rnorm(.N, pred_size, sigma_obs)]

  # calculate observed and predicted growth 
  val_sp[, obs_growth := (dbh - dbh0)/deltaTime]
  val_sp[, pred_growth := (pred_size - dbh0)/deltaTime]
  val_sp[, pred_growth_random := (pred_size_random - dbh0)/deltaTime]

  # calculate MSE
  val_sp[, SE_size := (dbh - pred_size_random)^2]
  val_sp[, SE_growth := (obs_growth - pred_growth_random)^2]

  # mean SE over all observations for each iteration and save to list
  MSE_list[[Sp]] <- val_sp[, 
    .(
      MSE_size = mean(SE_size, na.rm = TRUE),
      MSE_growth = mean(SE_growth, na.rm = TRUE),
      species_id = Sp
    ),
    by = iter2
  ]

  # Calculate R2 (Gelman et al 2018)
  R2gel <- val_sp |>
    group_by(iter2) |>
    summarise(var_size = var(pred_size, na.rm = TRUE)) |>
    bind_cols(iter = sampledIter) |>
    left_join(
      post |>
        filter(species_id == Sp & par == 'sigma_obs') |>
        mutate(sigma_obs = value) |>
        select(iter, sigma_obs, species_id)
    ) |>
    mutate(R2gelman_size = var_size/(var_size + sigma_obs^2)) |>
    select(iter, iter2, species_id, R2gelman_size) |>
    setDT()

  # calculate R2 from regression linear model using the 1:1 obs vs pred
  get_r2 <- function(x, y)
      return(summary(lm(y~x))$r.squared)
  
  R2_list[[Sp]] <- merge(
    R2gel,
    val_sp[,
      .(
        R2reg_size = get_r2(dbh, pred_size_random),
        R2reg_growth = get_r2(obs_growth, pred_growth_random),
        R2reg_size_mean = get_r2(dbh, pred_size),
        R2reg_growth_mean = get_r2(obs_growth, pred_growth)
      ), 
      by = iter2
    ],
    by = 'iter2'
  )

  ## plot

  # define species specific axis limits for growth
  yLim <- val_sp[, quantile(obs_growth, probs = c(0.005, .995), na.rm = T)]
  
  p1 <- val_sp[deltaTime > 0, .(m_obs = mean(dbh), m_pred = mean(pred_size)), by = obsID] |>
      ggplot(aes(m_obs, m_pred)) +
          geom_hex(bins = 100) +
          geom_abline(slope = 1, intercept = 0) + 
          tune::coord_obs_pred() +
          theme_minimal() +
          theme(
                legend.position="none",
                plot.margin = margin(t = 30)
            ) +
          xlab('Observerd size') +
          ylab('Predicted size')

  p2 <- val_sp[deltaTime > 0, .(m_obs = mean(obs_growth), m_pred = mean(pred_growth)), by = obsID] |>
      ggplot(aes(m_obs, m_pred)) +
          geom_hex(bins = 100) +
          geom_abline(slope = 1, intercept = 0) +
          xlim(yLim) + ylim(yLim) +
          theme_minimal() +
          theme(
                legend.position="none",
                plot.margin = margin(t = 30)
            ) +
          xlab('Observerd growth') +
          ylab('Predicted growth')

  pred_size_matrix <- val_sp[deltaTime > 0 & !is.na(pred_size_random), .(pred_size_random, iter2, obsID)] |>
      pivot_wider(names_from = obsID, values_from = pred_size_random) |>
      select(-iter2) |>
      as.matrix()

  p3 <- ppc_dens_overlay(
      val_sp[iter2 == 1 & deltaTime > 0, dbh],
      pred_size_matrix
  ) +
  xlab('Obs vs predicted size') + ylab('')

  pred_growth_matrix <- val_sp[deltaTime > 0 & !is.na(obs_growth) & !is.na(pred_growth), .(pred_growth_random, iter2, obsID)] |>
      pivot_wider(names_from = obsID, values_from = pred_growth_random) |>
      select(-iter2) |>
      as.matrix()

  p4 <- ppc_dens_overlay(
      val_sp[iter2 == 1 & deltaTime > 0 & !is.na(obs_growth), obs_growth],
      pred_growth_matrix
  ) +
  xlab('Obs vs predicted growth') +
  xlim(yLim)

  print(
    ggpubr::ggarrange(
        p1, p2, p3, p4,
        ncol = 2, nrow = 2,
        labels = Sp,
        font.label = list(size = 9, face = 'bold')
    )
  )
}

# save MSE and R2 to be used for model comparison
invisible(
    map_dfr(
    c('MSE', 'R2'),
    ~ get(paste0(.x, '_list')) |>
        bind_rows() |>
        saveRDS(file = file.path(
          'output', 
          simName,
          paste0(.x, '.RDS')
      )
    )
  )
)
```


# Mean squared error (MSE) of out-of-bag predictions

```{r plot_MSE, echo = FALSE, warning=FALSE, message=FALSE, fig.height = 8, fig.width = 9}
sim_toLoad <- c(simInfo$simCompare, simName)

  map_dfr(
    sim_toLoad,
    ~ readRDS(file.path('output', .x, 'MSE.RDS')) |>
      bind_cols(sim = .x)
  ) |>
  mutate(
    `Predicted size` = MSE_size,
    `Predicted growth` = MSE_growth
  ) |>
  select(-contains('MSE')) |>
  pivot_longer(
    cols = contains('Predicted')
  ) |>
  mutate(name2 = factor(name,  levels = c('Predicted size', 'Predicted growth'))) |>
  ggplot(aes(x = value, y = species_id, fill = sim)) +
    geom_density_ridges(alpha = 0.8, scale= 1.8, color = NA) +
    facet_wrap(~name2, scales = 'free_x') +
    xlab('Mean Squared error (MSE)') + ylab('') +
    theme_bw() + 
    theme(legend.position = 'bottom')
```


# Rsquared

The distribution of R squared values is calculated using the Gelman et al. [2018](http://www.stat.columbia.edu/~gelman/research/unpublished/bayes_R2.pdf) definition.

```{r plot Rsquared_gelman,echo=FALSE,fig.height = 7.5, fig.width = 8, warning=FALSE, message=FALSE}
map_dfr(
    sim_toLoad,
    ~ readRDS(file.path('output', .x, 'R2.RDS')) |>
      bind_cols(sim = .x)
  ) |>
  ggplot(aes(x = R2gelman_size, y = species_id, fill = sim)) +
      geom_density_ridges(alpha = 0.8, scale= 1.8, color = NA) +
      xlab('Rsquared (Gelman 2018)') +
      theme_minimal()
```

We also calculated the $R^2$ from the linear model using the 1:1 plot comparing observed values to the predicted values. This approach was used for the size predictions from the model, and the growth predictions derived from the size predictions.

```{r plot Rsquared_regression,echo=FALSE,fig.height = 8, fig.width = 9, warning=FALSE, message=FALSE}
map_dfr(
    sim_toLoad,
    ~ readRDS(file.path('output', .x, 'R2.RDS')) |>
      bind_cols(sim = .x)
  ) |>
  mutate(
    `R2 predicted size` = R2reg_size_mean,
    `R2 predicted growth` = R2reg_growth_mean
  ) |>
  select(species_id, iter2, sim, contains('R2 predicted')) |>
  pivot_longer(
    cols = contains('R2 predicted'),
    names_to = 'par',
    values_to = 'value'
  ) |>
  mutate(
    par2 = factor(par,  levels = c('R2 predicted size', 'R2 predicted growth'))
  ) |>
  ggplot(aes(x = value, y = species_id, fill = sim)) +
    geom_density_ridges(alpha = 0.8, scale= 1.8, color = NA) +
    facet_wrap(~par2, scales = 'free_x') +
    xlab('Rsquared (linear regression)') +
    theme_bw() +
    theme(legend.position = 'bottom')
```


# Intraclass Correlation Coefficient (ICC)

*I should not be using this for my kind of model but I will let it here anyway...*

```{r ICC,echo=FALSE,fig.height = 7.5, fig.width = 8, warning=FALSE, message=FALSE}
post |>
  filter(grepl('sigma', par)) |>
  pivot_wider(
    names_from = par,
    values_from = value
  ) |>
  group_by(species_id, iter) |>
  summarise(
    icc = sigma_plot/(sigma_plot + sigma_obs)
  ) |>
  saveRDS(
    file = paste0('output/', simName, '/ICC.RDS')
  )


# compare between all simulations with random effects
map_dfr(
    sim_toLoad,
    ~ readRDS(file.path('output', .x, 'ICC.RDS')) |>
      bind_cols(sim = .x)
  ) |>
  ggplot(aes(x = icc, y = species_id, fill = sim)) +
      geom_density_ridges(alpha = 0.8, scale= 1.8, color = NA) +
      xlab('ICC') +
      theme_minimal()

# ICC vs R2
map_dfr( 
    simName, 
    ~ readRDS(file.path('output', .x, 'R2.RDS')) |>
      left_join(
        readRDS(file.path('output', .x, 'ICC.RDS')),
        by = c('iter', 'species_id')
      )
  ) |>
  select(iter2, species_id, icc, R2reg_growth_mean) |>
  group_by(species_id) |>
  summarise(
    icc_mean = mean(icc),
    icc_min = quantile(icc, probs = .05),
    icc_max = quantile(icc, probs = .95),
    r2_mean = mean(R2reg_growth_mean),
    r2_min = quantile(R2reg_growth_mean, probs = .05),
    r2_max = quantile(R2reg_growth_mean, probs = .95)
  ) |>
  ggplot(aes(icc_mean, r2_mean, color = species_id)) +
    geom_point() +
    geom_errorbar(aes(ymin = r2_min, ymax = r2_max), alpha = .5) + 
    geom_errorbarh(aes(xmin = icc_min,xmax = icc_max), alpha = .5) +
    theme_minimal() +
    xlab('ICC') + ylab('Rsquared (linear regression)')
```

# Leave-one-out cross-validation to compare models

```{r loo, echo = FALSE, warning=FALSE,fig.height = 8, fig.width = 8, warning=FALSE, message=FALSE}
map_dfr(
    spIds,
    ~ map2(
        setNames(sim_toLoad, sim_toLoad),
        .x,
        ~ readRDS(paste0('output/', .x, '/loo_', .y, '.RDS'))
      ) |>
      loo::loo_compare() |>
      as.data.frame() |>
      bind_cols(species_id = .x) |>
      rownames_to_column(var = 'sim')
  ) |>
  select(species_id, sim, elpd_diff, se_diff) |>
  pivot_longer(
    cols = c(elpd_diff, se_diff),
    names_to = 'variable',
    values_to = 'value'
  ) |>
  ggplot(aes(x = value, y = species_id, color = sim)) +
    geom_point() +
    facet_wrap(~ variable, scales = 'free_x') +
    xlab('') + ylab('') +
    theme_bw() +
    theme(legend.position = 'bottom')
```


# Sampling time

```{r plot sampling time, echo = FALSE, fig.height = 7, fig.width = 8}
map2_dfr(
  diag_files,
  names(diag_files),
  ~ readRDS(.x)[['time']][['chains']] |>
    bind_cols(species_id = .y)
) |>
ggplot(aes(x = total/3600, y = species_id)) +
  geom_boxplot() +
  xlab('Fit time (hours)') +
  theme_minimal()
```
